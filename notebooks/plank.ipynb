{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    ToPILImage,\n",
    "    ToTensor,\n",
    ")\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlankFilter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=128 * 30 * 30, out_features=128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 128 * 30 * 30)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlankFilter(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=115200, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PlankFilter()\n",
    "model.load_state_dict(torch.load(\"./plank_filter.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_path1 = [\n",
    "    \"./camera_01_unnested/\",\n",
    "    \"./camera_02_unnested/\",\n",
    "    \"./camera_03_unnested/\",\n",
    "    \"./camera_04_unnested/\",\n",
    "    \"./camera_05_unnested/\",\n",
    "    \"./camera_06_unnested/\",\n",
    "    \"./camera_07_unnested/\",\n",
    "]\n",
    "\n",
    "camera_path2 = [\n",
    "    \"./camera_08_unnested/\",\n",
    "    \"./camera_09_unnested/\",\n",
    "    \"./camera_10_unnested/\",\n",
    "    \"./camera_11_unnested/\",\n",
    "    \"./camera_12_unnested/\",\n",
    "    \"./camera_13_unnested/\",\n",
    "    \"./camera_14_unnested/\",\n",
    "    \"./camera_15_unnested/\",\n",
    "    \"./camera_16_unnested/\"\n",
    "]\n",
    "\n",
    "img_pipeline = Compose(\n",
    "    [\n",
    "        ToPILImage(),\n",
    "        Resize((256, 256)),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Processing camera 8 ___\n",
      "13:55\n",
      "Processing Image          0\n",
      "Processing Image       5000\n",
      "Processing Image      10000\n",
      "Processing Image      15000\n",
      "Processing Image      20000\n",
      "Processing Image      25000\n",
      "Processing Image      30000\n",
      "Processing Image      35000\n",
      "Processing Image      40000\n",
      "Processing Image      45000\n",
      "Processing Image      50000\n",
      "Processing Image      55000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [32:27, 1947.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Processing camera 9 ___\n",
      "14:27\n",
      "Processing Image          0\n",
      "Processing Image       5000\n",
      "Processing Image      10000\n",
      "Processing Image      15000\n",
      "Processing Image      20000\n",
      "Processing Image      25000\n",
      "Processing Image      30000\n",
      "Processing Image      35000\n",
      "Processing Image      40000\n",
      "Processing Image      45000\n",
      "Processing Image      50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [1:01:12, 1816.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Processing camera 10 ___\n",
      "14:56\n",
      "Processing Image          0\n",
      "Processing Image       5000\n",
      "Processing Image      10000\n",
      "Processing Image      15000\n",
      "Processing Image      20000\n",
      "Processing Image      25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 440432 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 207907 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image      30000\n",
      "Processing Image      35000\n",
      "Processing Image      40000\n",
      "Processing Image      45000\n",
      "Processing Image      50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [1:31:13, 1809.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Processing camera 11 ___\n",
      "15:26\n",
      "Processing Image          0\n",
      "Processing Image       5000\n",
      "Processing Image      10000\n",
      "Processing Image      15000\n",
      "Processing Image      20000\n",
      "Processing Image      25000\n",
      "Processing Image      30000\n",
      "Processing Image      35000\n",
      "Processing Image      40000\n",
      "Processing Image      45000\n",
      "Processing Image      50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:59:43, 1770.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Processing camera 12 ___\n",
      "15:55\n",
      "Processing Image          0\n",
      "Processing Image       5000\n",
      "Processing Image      10000\n",
      "Processing Image      15000\n",
      "Processing Image      20000\n",
      "Processing Image      25000\n",
      "Processing Image      30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [2:15:25, 2031.49s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Image is incomplete or truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing Image \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m:\u001b[39;00m\u001b[39m >10\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[39m#print(cam_path + file, j)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     img \u001b[39m=\u001b[39m read_image(cam_path \u001b[39m+\u001b[39;49m file)\n\u001b[1;32m     13\u001b[0m     img \u001b[39m=\u001b[39m img_pipeline(img)\n\u001b[1;32m     14\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/arn/lib/python3.9/site-packages/torchvision/io/image.py:254\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    252\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m    253\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[0;32m--> 254\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/arn/lib/python3.9/site-packages/torchvision/io/image.py:231\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m    230\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[0;32m--> 231\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mdecode_image(\u001b[39minput\u001b[39;49m, mode\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/arn/lib/python3.9/site-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Image is incomplete or truncated"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, cam_path in tqdm(enumerate(camera_path2,8)):\n",
    "    print(f\"{'':_>3} Processing camera {i} {'':_>3}\")\n",
    "    print(f\"{datetime.now():%H:%M}\")\n",
    "    for j, file in enumerate(os.listdir(cam_path)):\n",
    "\n",
    "        if j % 5000 == 0:\n",
    "            print(f\"Processing Image {j: >10}\")\n",
    "        if file.endswith(\".jpg\"):\n",
    "            #print(cam_path + file, j)\n",
    "            img = read_image(cam_path + file)\n",
    "            img = img_pipeline(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                pred = model(img)\n",
    "            results.append(dict(\n",
    "                camera = i,\n",
    "                file = file,\n",
    "                plank = np.round(pred.item())\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera</th>\n",
       "      <th>file</th>\n",
       "      <th>plank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-17T16:49:49.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-11T16:54:36.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-31T05:34:06.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-04-13T14:58:13.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-03-29T17:38:49.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245442</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-04-17T11:34:29.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245443</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-04-16T09:59:34.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245444</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-04-16T12:51:21.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245445</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-02-28T08:38:23.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245446</th>\n",
       "      <td>12</td>\n",
       "      <td>2017-03-18T22:11:24.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        camera                     file  plank\n",
       "0            8  2017-03-17T16:49:49.jpg    1.0\n",
       "1            8  2017-03-11T16:54:36.jpg    1.0\n",
       "2            8  2017-03-31T05:34:06.jpg    1.0\n",
       "3            8  2017-04-13T14:58:13.jpg    1.0\n",
       "4            8  2017-03-29T17:38:49.jpg    1.0\n",
       "...        ...                      ...    ...\n",
       "245442      12  2017-04-17T11:34:29.jpg    1.0\n",
       "245443      12  2017-04-16T09:59:34.jpg    1.0\n",
       "245444      12  2017-04-16T12:51:21.jpg    1.0\n",
       "245445      12  2017-02-28T08:38:23.jpg    1.0\n",
       "245446      12  2017-03-18T22:11:24.jpg    1.0\n",
       "\n",
       "[245447 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"plank_results8-11.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('arn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f90e391dca8f8b979c746e60f5494ca9d42a24f5a0cc8a246e63e41ca743f4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
